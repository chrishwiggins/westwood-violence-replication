---
marp: true
theme: default
paginate: true
math: mathjax
style: |
  section {
    font-size: 24px;
  }
  code {
    font-size: 18px;
  }
  pre {
    font-size: 16px;
  }
  .small {
    font-size: 20px;
  }
---

# Reproducing "Current Research Overstates American Support for Political Violence"

**Westwood et al. (2022) PNAS**

DOI: 10.1073/pnas.2116870119

---

# Part 1: The Paper

## Core Claim

Prior survey research reports ~20% of Americans support political violence.

**Westwood et al. argue this is inflated by 3-8x** due to:
1. Survey satisficing (disengaged respondents)
2. Measurement error in abstract questions
3. Correlation inflation in correlates analysis

---

# The Problem: Survey Satisficing

**Satisficing** = respondents who don't engage with survey content

- Click through without reading
- Random or careless responses
- Fail comprehension checks

These respondents systematically inflate violence support estimates.

---

# Study Design Overview

| Study | Platform | Date | n | Design |
|-------|----------|------|---|--------|
| Study 1 | Qualtrics | Jan 2021 | 1,002 | Car-ramming vignette |
| Study 2 | Qualtrics | Apr 2021 | 1,023 | Shooting vignette |
| Study 3 | YouGov | Nov 2021 | 1,863 | Shooting (weighted) |
| Study 4 | Qualtrics | Jan 2021 | 1,009 | Sentencing task |

Total cost: ~$25,000 in survey fees

---

# The Engagement Screen

Respondents classified as **Engaged** or **Disengaged** based on comprehension:

```r
# preprocess1.R:127-129
study1$passed <- "Disengaged Respondent"
study1$passed[study1$Q43 == "Florida" &
              study1$partisantreatment==1] <- "Engaged Respondent"
study1$passed[study1$Q49 == "Oregon" &
              study1$partisantreatment==2] <- "Engaged Respondent"
```

Simple factual question: "In what state did the incident occur?"

---

# Key Finding: Engagement Matters

![bg right:45% fit](results/plot2.pdf)

**Study 1** (Political treatments):
- Engaged: 12.1%
- Disengaged: 37.9%
- Ratio: **3.1x**

**Study 2** (Political treatments):
- Engaged: 4.4%
- Disengaged: 33.8%
- Ratio: **7.7x**

---

# Figure 2: The Core Result

Three dependent variables across Studies 1-3:

**Panel A**: "Suspect is Justified"
**Panel B**: "Support for Suspect"
**Panel C**: "Suspect Should be Charged"

Orange = Disengaged (fail check)
Blue = Engaged (pass check)

Generated by `figure2.R` (232 lines)

---

# Code: Computing Engagement Differences

```r
# figure2.R:7-14
plot1ajustifieddata <- study1 %>%
  group_by(alignment, passed) %>%
  summarise(smean = mean(justified, na.rm = TRUE),
            ssd = sd(justified, na.rm = TRUE),
            count = n()) %>%
  mutate(se = ssd / sqrt(count),
         lower = lower_ci(smean, se, count),
         upper = upper_ci(smean, se, count))
```

Standard error: $SE = \frac{s}{\sqrt{n}}$

---

# Figure 1: Prior Estimates vs. Reality

![bg right:50% fit](results/plot_hist.pdf)

Distribution of Kalmoe-Mason (2019) derived estimates from media coverage.

Orange line: Disengaged median (~18.5%)
Blue line: Engaged median (~2.9%)

**6x inflation** in typical reporting

---

# Code: Figure 1 Histogram

```r
# figure1.R:5 - kme = "Kalmoe-Mason Estimates"
kme <- read_csv("../data/priorestimates.csv")

# figure1.R:22-36
all <- ggplot(data=kme[!is.na(kme$PartisansSupport),],
              aes(PartisansSupport)) +
  geom_histogram(bins=30, aes(y=..density..)) +
  geom_vline(xintercept=c(12.6), linetype="solid",
             size=2, color ="#D55E00") +  # Disengaged
  geom_vline(xintercept=c(2.2), linetype="solid",
             size=2, color="#0072B2") +   # Engaged
  xlab("Percent of Americans Supporting Violence")
```

---

# Figure 3: Response Distributions

![bg right:45% fit](results/plot3.pdf)

Distribution of responses by engagement status.

Disengaged respondents show:
- More uniform distributions
- Less differentiation by condition
- Classic satisficing pattern

---

# The Kalmoe-Mason Measure (2019)

Abstract question used in prior research:

> "When, if ever, is it OK for [party] to use violence?"

```r
# preprocess1.R:96-99
data$Q32 <- recode(data$Q32,
  "Strongly agree" = 5, "Somewhat agree" = 4,
  "Neither agree nor disagree" = 3,
  "Somewhat disagree" = 2, "Strongly disagree" = 1)
```

Problem: Abstract questions allow satisficing without detection.

---

# Figure 4: Interaction Effects

![bg right:45% fit](results/plot4.pdf)

Self-reported justification for violence (Q77) predicts vignette responses.

But relationship differs by treatment condition (alignment).

Generated using `effects` package for regression interaction visualization.

---

# Code: Figure 4 Regression

```r
# figure4.R:5-8
study1$Q77f <- as.factor(study1$Q77)
q77justified <- summary(lm(justified ~ alignment * Q77f,
                           data = study1))
eff <- effect(q77justified,
              term = "alignment * Q77f", as.table = T)
```

OLS with interaction: $Y = \beta_0 + \beta_1 \cdot \text{alignment} + \beta_2 \cdot \text{Q77} + \beta_3 \cdot (\text{alignment} \times \text{Q77})$

---

# Figure 5: Sentencing Task (Study 4)

![bg right:45% fit](results/plot5.pdf)

Concrete behavioral measure: proposed prison sentences.

Crimes: vandalism, assault, manslaughter

Tests whether respondents distinguish crime severity.

---

# Figure 6: Correlates Inflation

![bg right:45% fit](results/plot6.pdf)

**Panel A**: Aggression predicts passing engagement test
**Panel B**: Distribution of aggression by engagement

High aggression $\rightarrow$ more likely to be disengaged

This inflates aggression-violence correlations.

---

# Code: Figure 6 Analysis

```r
# figure6.R:5-20
prop <- ggplot(study2,
               aes(x = bussperryc01, y = passed01)) +
  geom_smooth(color="#D55E00", fill="#D55E00") +
  ylab("Proportion Passing Engagement Test") +
  scale_x_continuous(limits = c(0,1))
```

Buss-Perry Aggression Questionnaire (1992; 12 items, `preprocess1.R:78-91`)

---

# Correlates Inflation: The Math

If $\rho(\text{Aggression}, \text{Disengagement}) > 0$

And disengaged respondents inflate violence support...

Then $\rho(\text{Aggression}, \text{Violence Support})$ is **spuriously inflated**.

Paper finds:
- All respondents, K-M measure: r = 0.82
- Engaged only, precise measure: r = 0.20
- **4x inflation**

---

# Part 2: Partial Identification Bounds

What would disengaged respondents answer if they were truly engaged?

We can't observe this, but we can **bound** it.

---

# The Partial ID Model

Let:
- $Y$ = observed outcome (support violence)
- $C$ = engagement indicator (1 = passed check)
- $g$ = guess rate on comprehension check

True support among engaged population:
$$\theta \in \left[ E[Y] + \frac{a \cdot P(C=0) - E[Y(1-C)]}{1-g}, \; E[Y] + \frac{b \cdot P(C=0) - E[Y(1-C)]}{1-g} \right]$$

where $a, b$ bound what disengaged would answer if engaged.

---

# Code: Partial Bounds Function

```r
# partial_id_bounds.R:1-30
partial_bounds <- function(outcome, check, guess_rate,
                           a = 0, b = 1, conf_level = 0.95) {
  Delta_coef_lo <- c(1, a/(1-guess_rate), -1/(1-guess_rate))
  Delta_coef_hi <- c(1, b/(1-guess_rate), -1/(1-guess_rate))

  X <- cbind(outcome, (1 - check), outcome * (1 - check))
  Xbar <- colMeans(X)
  root_N <- sqrt(nrow(X))

  theta_lo <- c(Delta_coef_lo %*% Xbar)
  theta_hi <- c(Delta_coef_hi %*% Xbar)
  # ... variance via delta method
}
```

---

# Delta Method for Variance

The bounds are functions of sample means. Variance computed via:

$$\text{Var}(\hat{\theta}) = \nabla f(\bar{X})^T \cdot \text{Cov}(\bar{X}) \cdot \nabla f(\bar{X})$$

```r
# partial_id_bounds.R:13-16
V_X <- cov(X)
sd_lo <- sqrt(c(t(Delta_coef_lo) %*% V_X %*% Delta_coef_lo))
sd_hi <- sqrt(c(t(Delta_coef_hi) %*% V_X %*% Delta_coef_hi))
```

---

# Partial ID Results

With assumption that disengaged would answer 0-20% if engaged:

**95% CI for true support: [0.94%, 6.86%]**

```r
# partial_id_bounds.R:45-46
partial_bounds(outcome = study3partialID$y1,
               check = study3partialID$c,
               guess_rate = 1.0/7.0,
               a = 0, b = 0.25) * 100
```

Far below the 20%+ reported in prior research.

---

# Part 3: Reproducibility

## Data Availability

All materials on Harvard Dataverse:
- DOI: 10.7910/DVN/ZEHO8E
- 5 data files (.tab format)
- 25 R scripts

---

# Repository Structure

```
westwood-replication/
├── data/           # 5 CSV files (converted from .tab)
│   ├── study14.csv      (Studies 1 & 4)
│   ├── study25.csv      (Studies 2 & 5)
│   ├── study3.csv       (Study 3, YouGov)
│   ├── priorestimates.csv
│   └── newsCoverage2016-2021.csv
├── code/           # 25 R scripts (2,590 LOC total)
├── results/        # 6 PDF figures
└── supplement/     # SI Appendix (66+ tables)
```

---

# Code Statistics

| Category | Files | Lines |
|----------|-------|-------|
| Preprocessing | 5 | 423 |
| Figures | 7 | 630 |
| Core analysis | 4 | 236 |
| Appendix | 9 | 1,202 |
| Utilities | 2 | 99 |
| **Total** | **27** | **2,590** |

---

# Dependencies

```r
# run_core.R:2-12
library(dplyr)      # data manipulation
library(readr)      # CSV reading
library(ggplot2)    # plotting
library(tidyr)      # data reshaping
library(forcats)    # factor handling
library(cowplot)    # plot composition
library(stringr)    # string operations
library(effects)    # regression effects
library(Hmisc)      # weighted statistics
library(gtools)     # quantile binning
```

---

# Reproducibility Challenges Encountered

1. **Package compilation**: RcppArmadillo required C++14
   - Fix: Update `~/.R/Makevars` to not force C++11

2. **NA handling**: Study 3 had NA alignment values
   - Fix: Filter before weighted analysis (`figure2.R:26`)

3. **File format**: .tab files needed conversion to CSV

4. **SI Appendix**: Cloudflare protection required Playwright

---

# Code Fix: NA Alignment Issue

Original code failed on Study 3 weighted analysis:

```r
# figure2.R:25-32 (FIXED)
plot1cjustifieddata <- study3 %>%
  filter(!is.na(alignment)) %>%  # Added this line
  group_by(alignment, passed) %>%
  summarise(smean = weighted.mean(justified, w=weight, na.rm=TRUE),
            # ... weighted CI computation
            lower = weighted.ttest.ci(justified, weights=weight)[1],
            upper = weighted.ttest.ci(justified, weights=weight)[2])
```

---

# Weighted Analysis for YouGov Data

Study 3 uses survey weights for population representativeness:

```r
# functions.R:8-20
weighted.ttest.ci <- function(x, weights, conf.level = 0.95) {
  require(Hmisc)
  nx <- length(x)
  df <- nx - 1
  vx <- Hmisc::wtd.var(x, weights, normwt = TRUE)
  mx <- weighted.mean(x, weights)
  stderr <- sqrt(vx/nx)
  # ... t-distribution CI
}
```

---

# Sample Size Verification

Reproduced sample sizes match paper exactly:

| Study | Paper | Reproduced |
|-------|-------|------------|
| Study 1 | 1,002 | 1,002 |
| Study 2 | 1,023 | 1,023 |
| Study 3 | 1,863 | 1,863 |
| Study 4 | 1,009 | 1,009 |

```r
# run_core.R output
# Study 1 loaded: n = 1002
# Study 2 loaded: n = 1023
```

---

# Key Results Verification

**Study 1 - Political treatments:**
```
  passed                prop_justified     n
  Disengaged Respondent          0.379   169
  Engaged Respondent             0.121   315
```

**Study 2 - Political treatments:**
```
  passed                prop_justified     n
  Disengaged Respondent         0.338    136
  Engaged Respondent            0.0437   572
```

Matches paper's Figure 2 exactly.

---

# What Was Reproduced

| Item | Status |
|------|--------|
| Figure 1 (histogram) | Reproduced |
| Figure 2 (engagement effect) | Reproduced |
| Figure 3 (distributions) | Reproduced |
| Figure 4 (interactions) | Reproduced |
| Figure 5 (sentencing) | Reproduced |
| Figure 6 (correlates) | Reproduced |
| Partial ID bounds | Reproduced |
| Sample sizes | Verified |

---

# Statistical Methods Summary

1. **Proportions**: $\hat{p} \pm z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$

2. **Weighted means**: $\bar{x}_w = \frac{\sum w_i x_i}{\sum w_i}$

3. **OLS regression**: $Y = X\beta + \epsilon$

4. **Partial identification**: Bounds on unobserved counterfactual

5. **Delta method**: Variance of transformed statistics

---

# Implications for Survey Research

1. **Always include engagement checks**
   - Simple factual questions about vignettes
   - Screen or stratify by engagement

2. **Beware abstract questions**
   - "When is violence OK?" invites satisficing
   - Concrete vignettes reveal true attitudes

3. **Correlates may be spurious**
   - Disengagement correlates with many traits
   - Inflates apparent relationships

---

# The Bottom Line

Prior research reported ~20% support for political violence.

**True estimate: likely 2-7%**

The difference: survey satisficing, not political radicalization.

---

# Repository

GitHub: `chrishwiggins/westwood-violence-replication`

To reproduce:
```bash
cd westwood-replication/code
Rscript run_core.R
```

Output: 6 PDF figures in `results/`

---

# References

Westwood, S. J., Grimmer, J., Tyler, M., & Nall, C. (2022). Current research overstates American support for political violence. *Proceedings of the National Academy of Sciences*, 119(12), e2116870119.

Data: Harvard Dataverse, doi:10.7910/DVN/ZEHO8E

Code Ocean: doi:10.24433/CO.4651754.v1

---

# Appendix: File Reference

| File | Lines | Purpose |
|------|-------|---------|
| `preprocess1.R` | 165 | Study 1 & 4 data cleaning |
| `preprocess2.R` | 162 | Study 2 & 5 data cleaning |
| `preprocess3.R` | 21 | Study 3 (YouGov) cleaning |
| `figure2.R` | 232 | Core engagement effect plot |
| `partial_id_bounds.R` | 60 | Bounds computation |
| `functions.R` | 23 | CI and weighted stat helpers |

---

# Appendix: Key Variable Definitions

```r
# preprocess1.R:140-148
study1$justified <- recode(study1$justified,
                           "Justified" = 1,
                           "Unjustified" = 0)

study1$supportactions <- recode(study1$supportactions,
  "Strongly support" = 5, "Support" = 4,
  "Neither support nor oppose" = 3,
  "Oppose" = 2, "Strongly oppose" = 1)
```

Binary and Likert outcomes for robustness.
